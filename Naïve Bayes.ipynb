{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OihQBdUZw6Vg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import wordcloud\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn import metrics\n",
    "from keras.utils import np_utils\n",
    "#from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "from collections import defaultdict\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1048548 entries, 0 to 1048574\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype \n",
      "---  ------    --------------    ----- \n",
      " 0   polarity  1048548 non-null  int64 \n",
      " 1   title     1048548 non-null  object\n",
      " 2   text      1048548 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "# 3shan ashil error l AttributeError: 'float' object has no attribute 'lower'\n",
    "#data.SentimentText=data.SentimentText.astype(str)\n",
    "data = data.dropna()\n",
    "data.columns =['polarity','title','text',]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuations, stopwords, and lemmatize\n",
    "# pre processing now \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1048548"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head()\n",
    "print('\\n')\n",
    "data['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "\n",
    "def preprocess(document):\n",
    "    document = document.lower() # Convert to lowercase\n",
    "    words = tokenizer.tokenize(document) # Tokenize\n",
    "    words = [w for w in words if not w in stop_words] # Removing stopwords\n",
    "    # Lemmatizing\n",
    "    for pos in [wordnet.NOUN, wordnet.VERB, wordnet.ADJ, wordnet.ADV]:\n",
    "        words = [wordnet_lemmatizer.lemmatize(x, pos) for x in words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = wordcloud.WordCloud(background_color='gray', max_font_size=60, relative_scaling=1).generate(' '.join(data.text))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['yes_no'] = [1 if x > 2 else 0 for x in data.overall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    530148\n",
       "1    518400\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518400</td>\n",
       "      <td>517614</td>\n",
       "      <td>name</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>530148</td>\n",
       "      <td>529808</td>\n",
       "      <td>name</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text                   \n",
       "           count  unique   top freq\n",
       "polarity                           \n",
       "1         518400  517614  name    9\n",
       "2         530148  529808  name   21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data[[\"polarity\",\"text\"]]\n",
    "data2.groupby('polarity').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['polarity'], random_state=0,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    530148\n",
      "1    518400\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (786411,)\n",
      "y_train shape: (786411,)\n",
      "\n",
      "x_test shape: (262137,)\n",
      "y_test shape: (262137,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: {}\".format(x_train.shape), end='\\n')\n",
    "print(\"y_train shape: {}\".format(y_train.shape), end='\\n\\n')\n",
    "print(\"x_test shape: {}\".format(x_test.shape), end='\\n')\n",
    "print(\"y_test shape: {}\".format(y_test.shape), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614927    get seat son day ago love month old almost rea...\n",
       "88430     lie long dvd minute description disappoint als...\n",
       "380622    blink late release know untitled hype new blin...\n",
       "982426    thing readout scale instruction read htem swr ...\n",
       "775144    price device truly offer great value connectio...\n",
       "                                ...                        \n",
       "963421    love movie happy finally convenient video library\n",
       "117955    last great rush album hold fire two follow ok ...\n",
       "435841    thank diane believe feel ki part u high price ...\n",
       "305723    discuss son financial difficulty cpa recommend...\n",
       "985799    son month old absoutely love youtube gummy bea...\n",
       "Name: text, Length: 786411, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<786411x59524 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 24729004 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Vectorize X_train\n",
    "vectorizer = CountVectorizer(min_df=5).fit(x_train)\n",
    "X_train = vectorizer.transform(x_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 59524\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show some feature names : \n",
      " ['aa', 'agoraphobic', 'andwas', 'ascii', 'bal', 'berate', 'bondi', 'buendia', 'carre', 'chimera', 'colonize', 'conveyance', 'cubby', 'definitey', 'diga', 'doppelganger', 'edtv', 'epica', 'expesive', 'fiel', 'frame', 'geller', 'grafic', 'hancock', 'hidalgo', 'hussain', 'indoor', 'iranian', 'judo', 'korda', 'leonardi', 'lovingly', 'marengo', 'menard', 'mod', 'mutilation', 'noche', 'onces', 'pais', 'permission', 'poacher', 'prick', 'quaility', 'recomend', 'respectively', 'roti', 'scarwid', 'sexuality', 'skeleton', 'souther', 'sthe', 'supportees', 'teether', 'timbaland', 'trilok', 'undertanding', 'utmost', 'voraciously', 'wi', 'yasha']\n"
     ]
    }
   ],
   "source": [
    "print(\"Show some feature names : \\n\", vectorizer.get_feature_names()[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results  \n",
    "y_pred =mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8198575554004204\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.83      0.82    129319\n",
      "           2       0.83      0.81      0.82    132818\n",
      "\n",
      "    accuracy                           0.82    262137\n",
      "   macro avg       0.82      0.82      0.82    262137\n",
      "weighted avg       0.82      0.82      0.82    262137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "last.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
